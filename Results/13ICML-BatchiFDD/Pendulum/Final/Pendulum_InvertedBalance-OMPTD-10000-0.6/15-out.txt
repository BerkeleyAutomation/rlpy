============================================================
Domain:		Pendulum_InvertedBalance
Dimensions:	2
|S|:		inf
|A|:		3
|S|x|A|:		inf
Episode Cap:	3000
Gamma:		0.95
============================================================
Representation:		IndependentDiscretization
Features per action:	40
Discretization:		20
Starting Features:	40
Aggregated States:	400
============================================================
Representation:		iFDD
Features per action:	40
Discretization:		20
Starting Features:	40
Aggregated States:	400
Initial Representation:	IndependentDiscretization
Plus:			1
Sparsify:		0
Cached:			1
Online Threshold:	1.000
Batch Threshold:		0.000
Max Batch Discovery:	1
============================================================
Representation:		OMPTD
Features per action:	40
Discretization:		20
Starting Features:	40
Aggregated States:	400
Added 40 size 1 features to the feature bag.
Added 400 size 2 features to the feature bag.
Features:		40
Remaining Bag Size:	400
Initial Representation:	IndependentDiscretization
Bag Size:		440
Batch Threshold:		0.600
Max Batch Discovery:	20
============================================================
Agent:		RE_LSPI
Policy:		eGreedy
Max LSPI Iterations:	2
Data Size:		10000
Weight Difference tol.:	0.001
Max Representation Expansion Iterations:	2
============================================================
Experiment:		OnlineExperiment
Output:			Results/13ICML-BatchiFDD/Pendulum/Final//Pendulum_InvertedBalance-OMPTD-10000-0.6/15-results.txt
Learning Steps:		10000
Performance Checks:	1
Log Intervals:		1(s)
195: E[0:00:01]-R[0:00:53]: Return=-1.00, Steps=11, Features = 40
397: E[0:00:02]-R[0:00:51]: Return=-1.00, Steps=7, Features = 40
595: E[0:00:03]-R[0:00:49]: Return=-1.00, Steps=9, Features = 40
819: E[0:00:04]-R[0:00:46]: Return=-1.00, Steps=9, Features = 40
1015: E[0:00:05]-R[0:00:46]: Return=-1.00, Steps=13, Features = 40
1209: E[0:00:06]-R[0:00:45]: Return=-1.00, Steps=16, Features = 40
1397: E[0:00:07]-R[0:00:45]: Return=-1.00, Steps=9, Features = 40
1615: E[0:00:08]-R[0:00:43]: Return=-1.00, Steps=9, Features = 40
1831: E[0:00:09]-R[0:00:42]: Return=-1.00, Steps=10, Features = 40
2047: E[0:00:10]-R[0:00:40]: Return=-1.00, Steps=11, Features = 40
2277: E[0:00:11]-R[0:00:39]: Return=-1.00, Steps=10, Features = 40
2515: E[0:00:12]-R[0:00:37]: Return=-1.00, Steps=8, Features = 40
2756: E[0:00:13]-R[0:00:35]: Return=-1.00, Steps=19, Features = 40
2995: E[0:00:14]-R[0:00:34]: Return=-1.00, Steps=10, Features = 40
3233: E[0:00:15]-R[0:00:32]: Return=-1.00, Steps=12, Features = 40
3473: E[0:00:17]-R[0:00:31]: Return=-1.00, Steps=11, Features = 40
3708: E[0:00:18]-R[0:00:30]: Return=-1.00, Steps=10, Features = 40
3941: E[0:00:19]-R[0:00:29]: Return=-1.00, Steps=12, Features = 40
4184: E[0:00:20]-R[0:00:27]: Return=-1.00, Steps=8, Features = 40
4426: E[0:00:21]-R[0:00:26]: Return=-1.00, Steps=18, Features = 40
4652: E[0:00:22]-R[0:00:25]: Return=-1.00, Steps=14, Features = 40
4868: E[0:00:23]-R[0:00:24]: Return=-1.00, Steps=12, Features = 40
5088: E[0:00:24]-R[0:00:23]: Return=-1.00, Steps=11, Features = 40
5323: E[0:00:25]-R[0:00:22]: Return=-1.00, Steps=10, Features = 40
5540: E[0:00:26]-R[0:00:21]: Return=-1.00, Steps=11, Features = 40
5776: E[0:00:27]-R[0:00:20]: Return=-1.00, Steps=16, Features = 40
6001: E[0:00:28]-R[0:00:19]: Return=-1.00, Steps=10, Features = 40
6216: E[0:00:29]-R[0:00:18]: Return=-1.00, Steps=13, Features = 40
6440: E[0:00:30]-R[0:00:17]: Return=-1.00, Steps=8, Features = 40
6661: E[0:00:31]-R[0:00:16]: Return=-1.00, Steps=10, Features = 40
6880: E[0:00:32]-R[0:00:14]: Return=-1.00, Steps=13, Features = 40
7106: E[0:00:33]-R[0:00:13]: Return=-1.00, Steps=8, Features = 40
7328: E[0:00:34]-R[0:00:12]: Return=-1.00, Steps=11, Features = 40
7562: E[0:00:35]-R[0:00:11]: Return=-1.00, Steps=9, Features = 40
7792: E[0:00:36]-R[0:00:10]: Return=-1.00, Steps=11, Features = 40
8002: E[0:00:37]-R[0:00:09]: Return=-1.00, Steps=10, Features = 40
8234: E[0:00:38]-R[0:00:08]: Return=-1.00, Steps=8, Features = 40
8443: E[0:00:39]-R[0:00:07]: Return=-1.00, Steps=10, Features = 40
8646: E[0:00:40]-R[0:00:06]: Return=-1.00, Steps=10, Features = 40
8844: E[0:00:41]-R[0:00:05]: Return=-1.00, Steps=9, Features = 40
9057: E[0:00:42]-R[0:00:04]: Return=-1.00, Steps=7, Features = 40
9255: E[0:00:43]-R[0:00:03]: Return=-1.00, Steps=11, Features = 40
9457: E[0:00:44]-R[0:00:03]: Return=-1.00, Steps=8, Features = 40
9667: E[0:00:45]-R[0:00:02]: Return=-1.00, Steps=15, Features = 40
9876: E[0:00:46]-R[0:00:01]: Return=-1.00, Steps=10, Features = 40
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1.566, Density of A: 12.19%
2: L2_norm of weight difference = 0.137, Density of A: 12.53%
Performance Check >>> -1.000 Return, 1233 Steps, 40 Features
OMPTD Batch: Max Relevance = 0.786
New Feature 40: [10 25], Relevance = 0.786
New Feature 41: [10 26], Relevance = 0.740
New Feature 42: [ 9 34], Relevance = 0.713
New Feature 43: [ 8 32], Relevance = 0.702
New Feature 44: [ 9 33], Relevance = 0.676
New Feature 45: [11 27], Relevance = 0.644
New Feature 46: [ 8 30], Relevance = 0.622
New Feature 47: [11 29], Relevance = 0.609
New Feature 48: [ 9 36], Relevance = 0.604
Representation Expansion iteration #2
-----------------
Running LSPI:
1: L2_norm of weight difference = 2.236, Density of A: 9.71%
2: L2_norm of weight difference = 0.220, Density of A: 9.94%
Performance Check >>> 0.000 Return, 3000 Steps, 49 Features
OMPTD Batch: Max Relevance = 0.752
New Feature 49: [10 22], Relevance = 0.752
New Feature 50: [ 9 35], Relevance = 0.711
New Feature 51: [10 27], Relevance = 0.674
New Feature 52: [11 28], Relevance = 0.669
New Feature 53: [10 24], Relevance = 0.657
New Feature 54: [ 8 31], Relevance = 0.652
New Feature 55: [ 8 29], Relevance = 0.646
New Feature 56: [10 23], Relevance = 0.643
New Feature 57: [11 30], Relevance = 0.636
New Feature 58: [ 8 33], Relevance = 0.604
Running LSPI:
1: L2_norm of weight difference = 2.929, Density of A: 7.76%
2: L2_norm of weight difference = 0.562, Density of A: 7.91%
10000 >>> E[0:06:12]-R[0:00:00]: Return=+0.00, Steps=3000, Features = 59
============================================================
Took 0:06:12
Results	=> Results/13ICML-BatchiFDD/Pendulum/Final//Pendulum_InvertedBalance-OMPTD-10000-0.6/15-results.txt
Log	=> Results/13ICML-BatchiFDD/Pendulum/Final//Pendulum_InvertedBalance-OMPTD-10000-0.6/15-out.txt