============================================================
Domain:		SystemAdministrator
Dimensions:	20
|S|:		1048576
|A|:		21
|S|x|A|:		22020096
Episode Cap:	200
Gamma:		0.95
Computers:	20
Edges:		[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (0, 19)]
Neighbors:
0 : [1, 19]
1 : [0, 2]
2 : [1, 3]
3 : [2, 4]
4 : [3, 5]
5 : [4, 6]
6 : [5, 7]
7 : [6, 8]
8 : [7, 9]
9 : [8, 10]
10 : [9, 11]
11 : [10, 12]
12 : [11, 13]
13 : [12, 14]
14 : [13, 15]
15 : [14, 16]
16 : [15, 17]
17 : [16, 18]
18 : [17, 19]
19 : [18, 0]
============================================================
Representation:		IndependentDiscretizationCompactBinary
Features per action:	21
Binary Dimensions:	[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
============================================================
Representation:		iFDD
Features per action:	21
Initial Representation:	IndependentDiscretizationCompactBinary
Plus:			1
Sparsify:		1
Cached:			1
Online Threshold:	10.000
Batch Threshold:		1000.000
Max Batch Discovery:	100
============================================================
Agent:		RE_LSPI
Policy:		eGreedy
Max LSPI Iterations:	10
Data Size:		2500
Weight Difference tol.:	0.001
Max Representation Expansion Iterations:	20
============================================================
Experiment:		OnlineExperiment
Output:			././7-results.txt
Learning Steps:		20000
Performance Checks:	8
Log Intervals:		60(s)
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 653.733, Density of A: 32.30%
2: L2_norm of weight difference = 550.599, Density of A: 32.67%
3: L2_norm of weight difference = 3434.687, Density of A: 28.67%
4: L2_norm of weight difference = 3423.404, Density of A: 33.67%
5: L2_norm of weight difference = 7571.648, Density of A: 26.84%
6: L2_norm of weight difference = 7579.636, Density of A: 32.05%
7: L2_norm of weight difference = 2664.909, Density of A: 29.04%
8: L2_norm of weight difference = 2665.640, Density of A: 31.83%
9: L2_norm of weight difference = 126365.599, Density of A: 29.06%
10: L2_norm of weight difference = 126363.973, Density of A: 32.84%
Performance Check >>> 823.250 Return, 200 Steps, 21 Features
iFDD Batch: Max Relevance = 233900.273
New Feature 1: [15, 16], Relevance = 233900.273
New Feature 2: [3, 4], Relevance = 233124.409
New Feature 3: [4, 12], Relevance = 232153.656
New Feature 4: [8, 9], Relevance = 229233.116
New Feature 5: [10, 11], Relevance = 229174.759
New Feature 6: [9, 10], Relevance = 227289.374
New Feature 7: [4, 11], Relevance = 226793.329
New Feature 8: [14, 16], Relevance = 226693.279
New Feature 9: [8, 14], Relevance = 225789.189
New Feature 10: [8, 16], Relevance = 224186.242
New Feature 11: [16, 17], Relevance = 224176.129
New Feature 12: [4, 13], Relevance = 223696.704
New Feature 13: [9, 16], Relevance = 223062.275
New Feature 14: [0, 19], Relevance = 222781.411
New Feature 15: [11, 12], Relevance = 222314.289
New Feature 16: [9, 11], Relevance = 222242.756
New Feature 17: [9, 15], Relevance = 221885.167
New Feature 18: [14, 15], Relevance = 221411.246
New Feature 19: [15, 17], Relevance = 221055.506
New Feature 20: [2, 3], Relevance = 220971.586
New Feature 21: [10, 19], Relevance = 220962.104
New Feature 22: [8, 13], Relevance = 220451.263
New Feature 23: [4, 6], Relevance = 220440.555
New Feature 24: [6, 7], Relevance = 220300.749
New Feature 25: [6, 8], Relevance = 220199.780
New Feature 26: [4, 9], Relevance = 218787.934
New Feature 27: [8, 10], Relevance = 218558.052
New Feature 28: [6, 15], Relevance = 218369.690
New Feature 29: [0, 8], Relevance = 218304.086
New Feature 30: [4, 8], Relevance = 218234.568
New Feature 31: [2, 4], Relevance = 217974.279
New Feature 32: [5, 6], Relevance = 217937.016
New Feature 33: [11, 19], Relevance = 217633.389
New Feature 34: [0, 9], Relevance = 217523.740
New Feature 35: [12, 16], Relevance = 217022.407
New Feature 36: [4, 16], Relevance = 216676.559
New Feature 37: [11, 13], Relevance = 216478.732
New Feature 38: [11, 16], Relevance = 216338.045
New Feature 39: [12, 13], Relevance = 215468.371
New Feature 40: [8, 11], Relevance = 215391.729
New Feature 41: [10, 16], Relevance = 215236.669
New Feature 42: [6, 14], Relevance = 215112.558
New Feature 43: [2, 11], Relevance = 214869.739
New Feature 44: [6, 19], Relevance = 214857.271
New Feature 45: [6, 9], Relevance = 214804.271
New Feature 46: [4, 14], Relevance = 214795.837
New Feature 47: [3, 16], Relevance = 214635.356
New Feature 48: [10, 12], Relevance = 214564.013
New Feature 49: [13, 14], Relevance = 214537.014
New Feature 50: [3, 12], Relevance = 214141.558
New Feature 51: [6, 13], Relevance = 213667.480
New Feature 52: [3, 9], Relevance = 213291.028
New Feature 53: [9, 19], Relevance = 213074.231
New Feature 54: [7, 8], Relevance = 213000.612
New Feature 55: [0, 12], Relevance = 212636.347
New Feature 56: [6, 11], Relevance = 212302.063
New Feature 57: [12, 14], Relevance = 212285.489
New Feature 58: [13, 16], Relevance = 212238.597
New Feature 59: [12, 19], Relevance = 212043.795
New Feature 60: [5, 11], Relevance = 211804.308
New Feature 61: [9, 14], Relevance = 211645.086
New Feature 62: [16, 19], Relevance = 211379.541
New Feature 63: [4, 19], Relevance = 211229.649
New Feature 64: [4, 10], Relevance = 211197.543
New Feature 65: [9, 13], Relevance = 211173.505
New Feature 66: [0, 13], Relevance = 210902.919
New Feature 67: [5, 8], Relevance = 210878.805
New Feature 68: [8, 15], Relevance = 210033.377
New Feature 69: [12, 15], Relevance = 209510.831
New Feature 70: [0, 6], Relevance = 209504.565
New Feature 71: [2, 6], Relevance = 208643.577
New Feature 72: [0, 11], Relevance = 208398.827
New Feature 73: [5, 13], Relevance = 208253.314
New Feature 74: [6, 16], Relevance = 208224.419
New Feature 75: [3, 11], Relevance = 208215.139
New Feature 76: [3, 10], Relevance = 208068.607
New Feature 77: [10, 13], Relevance = 208043.033
New Feature 78: [6, 12], Relevance = 208000.325
New Feature 79: [0, 2], Relevance = 207830.265
New Feature 80: [0, 4], Relevance = 207610.938
New Feature 81: [8, 19], Relevance = 207117.434
New Feature 82: [4, 5], Relevance = 206833.574
New Feature 83: [0, 16], Relevance = 206673.228
New Feature 84: [4, 7], Relevance = 206487.134
New Feature 85: [6, 17], Relevance = 206372.997
New Feature 86: [7, 9], Relevance = 206319.464
New Feature 87: [17, 19], Relevance = 206288.586
New Feature 88: [2, 14], Relevance = 205970.755
New Feature 89: [0, 10], Relevance = 205853.121
New Feature 90: [5, 9], Relevance = 205725.177
New Feature 91: [11, 14], Relevance = 205508.480
New Feature 92: [15, 19], Relevance = 205481.102
New Feature 93: [9, 17], Relevance = 205468.523
New Feature 94: [0, 7], Relevance = 205074.296
New Feature 95: [4, 17], Relevance = 204921.113
New Feature 96: [3, 8], Relevance = 204908.874
New Feature 97: [9, 12], Relevance = 204759.167
New Feature 98: [1, 9], Relevance = 204674.465
New Feature 99: [2, 8], Relevance = 204621.643
New Feature 100: [12, 17], Relevance = 204340.797
Representation Expansion iteration #2
-----------------
Running LSPI:
1: L2_norm of weight difference = 1985.377, Density of A: 0.88%
2: L2_norm of weight difference = 535.654, Density of A: 0.89%
3: L2_norm of weight difference = 381.718, Density of A: 0.88%
4: L2_norm of weight difference = 385.526, Density of A: 0.88%
5: L2_norm of weight difference = 673.487, Density of A: 0.88%
6: L2_norm of weight difference = 780.058, Density of A: 0.89%
7: L2_norm of weight difference = 617.630, Density of A: 0.89%
8: L2_norm of weight difference = 661.069, Density of A: 0.88%
9: L2_norm of weight difference = 856.680, Density of A: 0.88%
10: L2_norm of weight difference = 1092.302, Density of A: 0.88%
Performance Check >>> 807.250 Return, 200 Steps, 121 Features
iFDD Batch: Max Relevance = 455.618
2500 >>> E[1:05:32]-R[7:38:45]: Return=911.25, Steps=200, Features = 121
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1118.690, Density of A: 0.65%
2: L2_norm of weight difference = 493.508, Density of A: 0.66%
3: L2_norm of weight difference = 614.308, Density of A: 0.66%
4: L2_norm of weight difference = 637.309, Density of A: 0.66%
5: L2_norm of weight difference = 582.805, Density of A: 0.65%
6: L2_norm of weight difference = 657.650, Density of A: 0.65%
7: L2_norm of weight difference = 670.823, Density of A: 0.65%
8: L2_norm of weight difference = 673.184, Density of A: 0.64%
9: L2_norm of weight difference = 681.367, Density of A: 0.66%
10: L2_norm of weight difference = 654.863, Density of A: 0.66%
Performance Check >>> 799.250 Return, 200 Steps, 121 Features
iFDD Batch: Max Relevance = 543.007
5000: E[2:01:17]-R[6:03:52]: Return=851.50, Steps=200, Features = 121
5000 >>> E[2:01:18]-R[6:03:53]: Return=759.50, Steps=200, Features = 121
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 843.400, Density of A: 0.57%
2: L2_norm of weight difference = 176.326, Density of A: 0.56%
3: L2_norm of weight difference = 169.311, Density of A: 0.56%
4: L2_norm of weight difference = 368.993, Density of A: 0.58%
5: L2_norm of weight difference = 698.234, Density of A: 0.56%
6: L2_norm of weight difference = 765.901, Density of A: 0.57%
7: L2_norm of weight difference = 664.012, Density of A: 0.57%
8: L2_norm of weight difference = 662.493, Density of A: 0.57%
9: L2_norm of weight difference = 659.051, Density of A: 0.56%
10: L2_norm of weight difference = 729.647, Density of A: 0.57%
Performance Check >>> 700.500 Return, 200 Steps, 121 Features
iFDD Batch: Max Relevance = 460.575
7500 >>> E[2:55:41]-R[4:52:48]: Return=682.25, Steps=200, Features = 121
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1092.406, Density of A: 0.65%
2: L2_norm of weight difference = 379.902, Density of A: 0.63%
3: L2_norm of weight difference = 509.964, Density of A: 0.64%
4: L2_norm of weight difference = 564.937, Density of A: 0.62%
5: L2_norm of weight difference = 572.790, Density of A: 0.64%
6: L2_norm of weight difference = 675.439, Density of A: 0.63%
7: L2_norm of weight difference = 682.134, Density of A: 0.64%
8: L2_norm of weight difference = 823.580, Density of A: 0.63%
9: L2_norm of weight difference = 935.631, Density of A: 0.62%
10: L2_norm of weight difference = 904.540, Density of A: 0.63%
Performance Check >>> 764.250 Return, 200 Steps, 121 Features
iFDD Batch: Max Relevance = 744.673
10000: E[3:50:39]-R[3:50:39]: Return=803.50, Steps=200, Features = 121
10000 >>> E[3:50:40]-R[3:50:40]: Return=1069.25, Steps=200, Features = 121
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1190.065, Density of A: 0.64%
2: L2_norm of weight difference = 180.383, Density of A: 0.65%
3: L2_norm of weight difference = 178.705, Density of A: 0.65%
4: L2_norm of weight difference = 389.842, Density of A: 0.64%
5: L2_norm of weight difference = 741.924, Density of A: 0.62%
6: L2_norm of weight difference = 864.844, Density of A: 0.64%
7: L2_norm of weight difference = 826.401, Density of A: 0.64%
8: L2_norm of weight difference = 942.099, Density of A: 0.66%
9: L2_norm of weight difference = 963.462, Density of A: 0.64%
10: L2_norm of weight difference = 945.205, Density of A: 0.63%
Performance Check >>> 865.750 Return, 200 Steps, 121 Features
iFDD Batch: Max Relevance = 746.301
12500 >>> E[4:46:21]-R[2:51:49]: Return=652.25, Steps=200, Features = 121
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 930.963, Density of A: 0.61%
2: L2_norm of weight difference = 284.194, Density of A: 0.61%
3: L2_norm of weight difference = 310.874, Density of A: 0.62%
4: L2_norm of weight difference = 327.660, Density of A: 0.62%
5: L2_norm of weight difference = 373.831, Density of A: 0.62%
6: L2_norm of weight difference = 410.471, Density of A: 0.62%
7: L2_norm of weight difference = 450.773, Density of A: 0.62%
8: L2_norm of weight difference = 479.727, Density of A: 0.61%
9: L2_norm of weight difference = 506.612, Density of A: 0.62%
10: L2_norm of weight difference = 552.643, Density of A: 0.61%
Performance Check >>> 714.000 Return, 200 Steps, 121 Features
iFDD Batch: Max Relevance = 331.748
15000: E[5:41:50]-R[1:53:57]: Return=786.75, Steps=200, Features = 121
15000 >>> E[5:41:50]-R[1:53:57]: Return=795.25, Steps=200, Features = 121
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1103.938, Density of A: 0.69%
2: L2_norm of weight difference = 227.924, Density of A: 0.69%
3: L2_norm of weight difference = 324.854, Density of A: 0.69%
4: L2_norm of weight difference = 477.037, Density of A: 0.70%
5: L2_norm of weight difference = 524.545, Density of A: 0.69%
6: L2_norm of weight difference = 539.150, Density of A: 0.70%
7: L2_norm of weight difference = 581.726, Density of A: 0.69%
8: L2_norm of weight difference = 596.221, Density of A: 0.69%
9: L2_norm of weight difference = 603.765, Density of A: 0.69%
10: L2_norm of weight difference = 608.440, Density of A: 0.69%
Performance Check >>> 764.500 Return, 200 Steps, 121 Features
iFDD Batch: Max Relevance = 479.197
17500 >>> E[6:38:43]-R[0:56:58]: Return=885.25, Steps=200, Features = 121
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1038.311, Density of A: 0.63%
2: L2_norm of weight difference = 369.518, Density of A: 0.62%
3: L2_norm of weight difference = 498.760, Density of A: 0.60%
4: L2_norm of weight difference = 601.304, Density of A: 0.62%
5: L2_norm of weight difference = 608.248, Density of A: 0.63%
6: L2_norm of weight difference = 631.674, Density of A: 0.62%
7: L2_norm of weight difference = 567.768, Density of A: 0.62%
8: L2_norm of weight difference = 500.218, Density of A: 0.62%
9: L2_norm of weight difference = 468.825, Density of A: 0.61%
10: L2_norm of weight difference = 451.443, Density of A: 0.61%
Performance Check >>> 603.250 Return, 200 Steps, 121 Features
iFDD Batch: Max Relevance = 304.376
20000: E[7:34:04]-R[0:00:00]: Return=829.50, Steps=200, Features = 121
20000 >>> E[7:34:05]-R[0:00:00]: Return=882.00, Steps=200, Features = 121
============================================================
Took 7:34:05
Results	=> ././7-results.txt
Log	=> ././7-out.txt