============================================================
Domain:		SystemAdministrator
Dimensions:	20
|S|:		1048576
|A|:		21
|S|x|A|:		22020096
Episode Cap:	200
Gamma:		0.95
Computers:	20
Edges:		[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (0, 19)]
Neighbors:
0 : [1, 19]
1 : [0, 2]
2 : [1, 3]
3 : [2, 4]
4 : [3, 5]
5 : [4, 6]
6 : [5, 7]
7 : [6, 8]
8 : [7, 9]
9 : [8, 10]
10 : [9, 11]
11 : [10, 12]
12 : [11, 13]
13 : [12, 14]
14 : [13, 15]
15 : [14, 16]
16 : [15, 17]
17 : [16, 18]
18 : [17, 19]
19 : [18, 0]
============================================================
Representation:		IndependentDiscretizationCompactBinary
Features per action:	21
Binary Dimensions:	[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
============================================================
Representation:		iFDD
Features per action:	21
Initial Representation:	IndependentDiscretizationCompactBinary
Plus:			1
Sparsify:		1
Cached:			1
Online Threshold:	10.000
Batch Threshold:		600.000
Max Batch Discovery:	100
============================================================
Agent:		RE_LSPI
Policy:		eGreedy
Max LSPI Iterations:	10
Data Size:		2500
Weight Difference tol.:	0.001
Max Representation Expansion Iterations:	20
============================================================
Experiment:		OnlineExperiment
Output:			././20-results.txt
Learning Steps:		20000
Performance Checks:	8
Log Intervals:		60(s)
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 503.423, Density of A: 31.14%
2: L2_norm of weight difference = 401.505, Density of A: 30.17%
3: L2_norm of weight difference = 895.582, Density of A: 29.90%
4: L2_norm of weight difference = 895.891, Density of A: 27.65%
5: L2_norm of weight difference = 27762.537, Density of A: 28.27%
6: L2_norm of weight difference = 28048.804, Density of A: 22.90%
7: L2_norm of weight difference = 300.874, Density of A: 29.10%
8: L2_norm of weight difference = 1430.065, Density of A: 28.47%
9: L2_norm of weight difference = 1430.835, Density of A: 27.59%
10: L2_norm of weight difference = 1237.531, Density of A: 28.80%
Performance Check >>> 475.750 Return, 200 Steps, 21 Features
iFDD Batch: Max Relevance = 213.850
2500 >>> E[0:01:35]-R[0:11:05]: Return=612.00, Steps=200, Features = 21
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 261.158, Density of A: 13.14%
2: L2_norm of weight difference = 125.653, Density of A: 14.44%
3: L2_norm of weight difference = 109.829, Density of A: 14.48%
4: L2_norm of weight difference = 240.444, Density of A: 14.70%
5: L2_norm of weight difference = 241.384, Density of A: 13.04%
6: L2_norm of weight difference = 115.075, Density of A: 13.80%
7: L2_norm of weight difference = 139.187, Density of A: 14.92%
8: L2_norm of weight difference = 140.002, Density of A: 14.74%
9: L2_norm of weight difference = 152.812, Density of A: 15.39%
10: L2_norm of weight difference = 149.205, Density of A: 14.51%
Performance Check >>> 742.000 Return, 200 Steps, 21 Features
iFDD Batch: Max Relevance = 549.991
5000: E[0:03:13]-R[0:09:38]: Return=548.25, Steps=200, Features = 21
5000 >>> E[0:03:14]-R[0:09:41]: Return=750.00, Steps=200, Features = 21
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 361.508, Density of A: 10.79%
2: L2_norm of weight difference = 111.249, Density of A: 10.25%
3: L2_norm of weight difference = 110.686, Density of A: 12.34%
4: L2_norm of weight difference = 136.447, Density of A: 12.62%
5: L2_norm of weight difference = 141.032, Density of A: 11.63%
6: L2_norm of weight difference = 109.504, Density of A: 12.07%
7: L2_norm of weight difference = 104.044, Density of A: 12.20%
8: L2_norm of weight difference = 98.480, Density of A: 12.34%
9: L2_norm of weight difference = 99.802, Density of A: 11.77%
10: L2_norm of weight difference = 101.500, Density of A: 12.09%
Performance Check >>> 679.000 Return, 200 Steps, 21 Features
iFDD Batch: Max Relevance = 345.843
7500 >>> E[0:05:11]-R[0:08:39]: Return=518.25, Steps=200, Features = 21
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 421.991, Density of A: 14.48%
2: L2_norm of weight difference = 284.768, Density of A: 14.16%
3: L2_norm of weight difference = 289.853, Density of A: 13.73%
4: L2_norm of weight difference = 332.439, Density of A: 15.87%
5: L2_norm of weight difference = 373.875, Density of A: 16.74%
6: L2_norm of weight difference = 243.539, Density of A: 16.71%
7: L2_norm of weight difference = 272.384, Density of A: 16.40%
8: L2_norm of weight difference = 297.495, Density of A: 15.79%
9: L2_norm of weight difference = 304.140, Density of A: 16.09%
10: L2_norm of weight difference = 278.679, Density of A: 16.56%
Performance Check >>> 620.000 Return, 200 Steps, 21 Features
iFDD Batch: Max Relevance = 819.674
New Feature 1: [14, 16], Relevance = 819.674
New Feature 2: [16, 18], Relevance = 795.068
New Feature 3: [18, 19], Relevance = 790.589
New Feature 4: [14, 18], Relevance = 768.507
New Feature 5: [17, 18], Relevance = 733.276
New Feature 6: [14, 19], Relevance = 726.323
New Feature 7: [6, 18], Relevance = 698.044
New Feature 8: [6, 14], Relevance = 695.339
New Feature 9: [11, 16], Relevance = 682.925
New Feature 10: [2, 18], Relevance = 681.481
New Feature 11: [16, 17], Relevance = 680.816
New Feature 12: [13, 14], Relevance = 676.177
New Feature 13: [5, 14], Relevance = 675.008
New Feature 14: [0, 18], Relevance = 674.787
New Feature 15: [5, 6], Relevance = 672.488
New Feature 16: [14, 15], Relevance = 667.186
New Feature 17: [0, 19], Relevance = 666.580
New Feature 18: [17, 19], Relevance = 665.468
New Feature 19: [0, 14], Relevance = 656.962
New Feature 20: [10, 18], Relevance = 655.838
New Feature 21: [5, 18], Relevance = 651.199
New Feature 22: [12, 18], Relevance = 647.599
New Feature 23: [13, 18], Relevance = 640.405
New Feature 24: [14, 17], Relevance = 634.076
New Feature 25: [16, 19], Relevance = 626.249
New Feature 26: [6, 19], Relevance = 622.895
New Feature 27: [12, 19], Relevance = 622.801
New Feature 28: [1, 14], Relevance = 621.341
New Feature 29: [11, 18], Relevance = 617.863
New Feature 30: [5, 16], Relevance = 617.377
New Feature 31: [0, 6], Relevance = 616.560
New Feature 32: [6, 12], Relevance = 615.251
New Feature 33: [10, 16], Relevance = 610.377
New Feature 34: [5, 19], Relevance = 609.486
New Feature 35: [4, 18], Relevance = 609.108
New Feature 36: [12, 14], Relevance = 608.548
New Feature 37: [7, 14], Relevance = 605.982
New Feature 38: [6, 16], Relevance = 605.275
New Feature 39: [3, 18], Relevance = 604.761
New Feature 40: [3, 19], Relevance = 603.966
New Feature 41: [10, 19], Relevance = 600.753
Representation Expansion iteration #2
-----------------
Running LSPI:
1: L2_norm of weight difference = 707.773, Density of A: 2.01%
2: L2_norm of weight difference = 346.980, Density of A: 2.05%
3: L2_norm of weight difference = 307.730, Density of A: 2.08%
4: L2_norm of weight difference = 320.133, Density of A: 2.14%
5: L2_norm of weight difference = 337.952, Density of A: 1.99%
6: L2_norm of weight difference = 347.872, Density of A: 2.06%
7: L2_norm of weight difference = 336.289, Density of A: 1.98%
8: L2_norm of weight difference = 359.243, Density of A: 1.97%
9: L2_norm of weight difference = 313.150, Density of A: 2.12%
10: L2_norm of weight difference = 286.359, Density of A: 1.95%
Performance Check >>> 607.000 Return, 200 Steps, 62 Features
iFDD Batch: Max Relevance = 455.339
10000: E[0:22:39]-R[0:22:39]: Return=759.00, Steps=200, Features = 62
10000 >>> E[0:22:40]-R[0:22:40]: Return=576.75, Steps=200, Features = 62
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 824.596, Density of A: 1.96%
2: L2_norm of weight difference = 668.827, Density of A: 2.12%
3: L2_norm of weight difference = 212.264, Density of A: 2.09%
4: L2_norm of weight difference = 210.322, Density of A: 2.13%
5: L2_norm of weight difference = 238.745, Density of A: 2.11%
6: L2_norm of weight difference = 209.590, Density of A: 2.17%
7: L2_norm of weight difference = 213.898, Density of A: 2.09%
8: L2_norm of weight difference = 221.156, Density of A: 2.09%
9: L2_norm of weight difference = 187.683, Density of A: 2.08%
10: L2_norm of weight difference = 206.497, Density of A: 2.13%
Performance Check >>> 701.000 Return, 200 Steps, 62 Features
iFDD Batch: Max Relevance = 392.371
12500 >>> E[0:35:43]-R[0:21:26]: Return=743.75, Steps=200, Features = 62
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 592.630, Density of A: 2.30%
2: L2_norm of weight difference = 189.401, Density of A: 2.25%
3: L2_norm of weight difference = 154.639, Density of A: 2.39%
4: L2_norm of weight difference = 179.810, Density of A: 2.54%
5: L2_norm of weight difference = 207.457, Density of A: 2.44%
6: L2_norm of weight difference = 852.772, Density of A: 2.35%
7: L2_norm of weight difference = 927.425, Density of A: 2.35%
8: L2_norm of weight difference = 997.810, Density of A: 2.33%
9: L2_norm of weight difference = 921.073, Density of A: 2.38%
10: L2_norm of weight difference = 935.188, Density of A: 2.19%
Performance Check >>> 861.750 Return, 200 Steps, 62 Features
iFDD Batch: Max Relevance = 1963.722
New Feature 1: [6, 15, 16], Relevance = 1963.722
New Feature 2: [6, 13, 16], Relevance = 1896.515
New Feature 3: [6, 9, 16], Relevance = 1870.430
New Feature 4: [5, 6, 16], Relevance = 1863.894
New Feature 5: [6, 8, 16], Relevance = 1862.488
New Feature 6: [6, 16, 17], Relevance = 1825.246
New Feature 7: [4, 6, 16], Relevance = 1820.886
New Feature 8: [2, 6, 16], Relevance = 1800.732
New Feature 9: [1, 6, 16], Relevance = 1770.280
New Feature 10: [6, 11, 16], Relevance = 1764.689
New Feature 11: [0, 6, 16], Relevance = 1763.909
New Feature 12: [6, 10, 16, 19], Relevance = 1626.510
New Feature 13: [6, 7, 14, 16], Relevance = 1549.360
New Feature 14: [11, 17], Relevance = 1528.439
New Feature 15: [1, 17], Relevance = 1481.589
New Feature 16: [6, 12, 16], Relevance = 1477.198
New Feature 17: [0, 17], Relevance = 1467.428
New Feature 18: [13, 17], Relevance = 1465.144
New Feature 19: [0, 13], Relevance = 1461.031
New Feature 20: [5, 13], Relevance = 1413.466
New Feature 21: [1, 13], Relevance = 1411.044
New Feature 22: [4, 17], Relevance = 1408.339
New Feature 23: [0, 10, 19], Relevance = 1400.825
New Feature 24: [9, 17], Relevance = 1395.775
New Feature 25: [7, 12, 14], Relevance = 1395.663
New Feature 26: [0, 11], Relevance = 1383.060
New Feature 27: [2, 17], Relevance = 1379.102
New Feature 28: [1, 2], Relevance = 1378.206
New Feature 29: [15, 17], Relevance = 1372.337
New Feature 30: [5, 17], Relevance = 1371.441
New Feature 31: [2, 13], Relevance = 1370.162
New Feature 32: [4, 13], Relevance = 1367.325
New Feature 33: [7, 13, 14], Relevance = 1366.587
New Feature 34: [5, 8], Relevance = 1366.502
New Feature 35: [0, 7, 14], Relevance = 1363.404
New Feature 36: [0, 8], Relevance = 1357.782
New Feature 37: [0, 5], Relevance = 1354.332
New Feature 38: [1, 11], Relevance = 1352.579
New Feature 39: [5, 15], Relevance = 1350.219
New Feature 40: [2, 5], Relevance = 1336.754
New Feature 41: [1, 5], Relevance = 1329.807
New Feature 42: [0, 4], Relevance = 1321.444
New Feature 43: [10, 17, 19], Relevance = 1321.032
New Feature 44: [3, 6, 16, 18], Relevance = 1315.500
New Feature 45: [5, 11], Relevance = 1308.311
New Feature 46: [11, 13], Relevance = 1307.593
New Feature 47: [5, 7, 14], Relevance = 1304.051
New Feature 48: [2, 15], Relevance = 1300.223
New Feature 49: [8, 13], Relevance = 1299.437
New Feature 50: [8, 17], Relevance = 1297.642
New Feature 51: [1, 15], Relevance = 1287.483
New Feature 52: [0, 1], Relevance = 1287.279
New Feature 53: [7, 14, 17], Relevance = 1282.265
New Feature 54: [5, 10, 19], Relevance = 1280.752
New Feature 55: [5, 9], Relevance = 1279.990
New Feature 56: [13, 15], Relevance = 1273.435
New Feature 57: [7, 8, 14], Relevance = 1271.580
New Feature 58: [12, 13], Relevance = 1264.778
New Feature 59: [0, 15], Relevance = 1262.926
New Feature 60: [9, 13], Relevance = 1262.215
New Feature 61: [0, 9], Relevance = 1258.224
New Feature 62: [7, 11, 14], Relevance = 1255.722
New Feature 63: [4, 5], Relevance = 1250.589
New Feature 64: [8, 15], Relevance = 1249.087
New Feature 65: [10, 13, 19], Relevance = 1248.237
New Feature 66: [12, 17], Relevance = 1246.525
New Feature 67: [4, 15], Relevance = 1245.381
New Feature 68: [2, 4], Relevance = 1232.821
New Feature 69: [1, 10, 19], Relevance = 1225.452
New Feature 70: [8, 9], Relevance = 1223.260
New Feature 71: [3, 17, 18], Relevance = 1221.953
New Feature 72: [1, 9], Relevance = 1221.416
New Feature 73: [4, 8], Relevance = 1220.584
New Feature 74: [9, 15], Relevance = 1220.415
New Feature 75: [8, 11], Relevance = 1220.229
New Feature 76: [1, 4], Relevance = 1219.573
New Feature 77: [11, 15], Relevance = 1218.181
New Feature 78: [0, 3, 18], Relevance = 1214.350
New Feature 79: [2, 9], Relevance = 1212.316
New Feature 80: [6, 12, 14, 16], Relevance = 1203.789
New Feature 81: [7, 9, 14], Relevance = 1201.287
New Feature 82: [9, 11], Relevance = 1198.314
New Feature 83: [3, 15, 18], Relevance = 1190.379
New Feature 84: [1, 7, 14], Relevance = 1188.547
New Feature 85: [4, 11], Relevance = 1188.513
New Feature 86: [1, 3, 18], Relevance = 1186.144
New Feature 87: [0, 2], Relevance = 1185.110
New Feature 88: [10, 15, 19], Relevance = 1183.829
New Feature 89: [0, 12], Relevance = 1183.391
New Feature 90: [8, 12], Relevance = 1181.906
New Feature 91: [9, 10, 19], Relevance = 1170.655
New Feature 92: [2, 7, 14], Relevance = 1165.653
New Feature 93: [2, 8], Relevance = 1165.112
New Feature 94: [3, 5, 18], Relevance = 1162.586
New Feature 95: [5, 12], Relevance = 1162.025
New Feature 96: [1, 8], Relevance = 1161.940
New Feature 97: [4, 9], Relevance = 1157.303
New Feature 98: [3, 8, 18], Relevance = 1149.395
New Feature 99: [8, 10, 19], Relevance = 1148.102
New Feature 100: [7, 10, 14, 19], Relevance = 1146.532
Representation Expansion iteration #2
-----------------
Running LSPI:
1: L2_norm of weight difference = 1085.078, Density of A: 0.30%
2: L2_norm of weight difference = 479.622, Density of A: 0.29%
3: L2_norm of weight difference = 549.221, Density of A: 0.30%
4: L2_norm of weight difference = 695.573, Density of A: 0.30%
5: L2_norm of weight difference = 760.917, Density of A: 0.30%
6: L2_norm of weight difference = 798.544, Density of A: 0.30%
7: L2_norm of weight difference = 824.566, Density of A: 0.30%
8: L2_norm of weight difference = 857.673, Density of A: 0.30%
9: L2_norm of weight difference = 879.667, Density of A: 0.30%
10: L2_norm of weight difference = 860.881, Density of A: 0.30%
Performance Check >>> 804.750 Return, 200 Steps, 162 Features
iFDD Batch: Max Relevance = 479.289
15000: E[3:03:05]-R[1:01:02]: Return=849.25, Steps=200, Features = 162
15000 >>> E[3:03:05]-R[1:01:02]: Return=798.00, Steps=200, Features = 162
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1094.124, Density of A: 0.31%
2: L2_norm of weight difference = 833.690, Density of A: 0.31%
3: L2_norm of weight difference = 841.695, Density of A: 0.32%
4: L2_norm of weight difference = 823.213, Density of A: 0.31%
5: L2_norm of weight difference = 864.408, Density of A: 0.31%
6: L2_norm of weight difference = 882.682, Density of A: 0.31%
7: L2_norm of weight difference = 814.818, Density of A: 0.31%
8: L2_norm of weight difference = 815.973, Density of A: 0.31%
9: L2_norm of weight difference = 824.789, Density of A: 0.31%
10: L2_norm of weight difference = 858.481, Density of A: 0.31%
Performance Check >>> 759.750 Return, 200 Steps, 162 Features
iFDD Batch: Max Relevance = 342.483
17500 >>> E[5:22:26]-R[0:46:04]: Return=684.00, Steps=200, Features = 162
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1129.644, Density of A: 0.32%
2: L2_norm of weight difference = 727.179, Density of A: 0.32%
3: L2_norm of weight difference = 836.846, Density of A: 0.32%
4: L2_norm of weight difference = 885.177, Density of A: 0.32%
5: L2_norm of weight difference = 865.772, Density of A: 0.32%
6: L2_norm of weight difference = 857.537, Density of A: 0.32%
7: L2_norm of weight difference = 844.654, Density of A: 0.32%
8: L2_norm of weight difference = 833.325, Density of A: 0.32%
9: L2_norm of weight difference = 826.439, Density of A: 0.32%
10: L2_norm of weight difference = 844.642, Density of A: 0.32%
Performance Check >>> 610.000 Return, 200 Steps, 162 Features
iFDD Batch: Max Relevance = 431.968
20000: E[7:33:36]-R[0:00:00]: Return=921.50, Steps=200, Features = 162
20000 >>> E[7:33:37]-R[0:00:00]: Return=768.25, Steps=200, Features = 162
============================================================
Took 7:33:37
Results	=> ././20-results.txt
Log	=> ././20-out.txt