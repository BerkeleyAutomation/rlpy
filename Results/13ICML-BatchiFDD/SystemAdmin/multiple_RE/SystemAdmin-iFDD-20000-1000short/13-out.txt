============================================================
Domain:		SystemAdministrator
Dimensions:	20
|S|:		1048576
|A|:		21
|S|x|A|:		22020096
Episode Cap:	200
Gamma:		0.95
Computers:	20
Edges:		[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (0, 19)]
Neighbors:
0 : [1, 19]
1 : [0, 2]
2 : [1, 3]
3 : [2, 4]
4 : [3, 5]
5 : [4, 6]
6 : [5, 7]
7 : [6, 8]
8 : [7, 9]
9 : [8, 10]
10 : [9, 11]
11 : [10, 12]
12 : [11, 13]
13 : [12, 14]
14 : [13, 15]
15 : [14, 16]
16 : [15, 17]
17 : [16, 18]
18 : [17, 19]
19 : [18, 0]
============================================================
Representation:		IndependentDiscretizationCompactBinary
Features per action:	21
Binary Dimensions:	[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
============================================================
Representation:		iFDD
Features per action:	21
Initial Representation:	IndependentDiscretizationCompactBinary
Plus:			1
Sparsify:		1
Cached:			1
Online Threshold:	10.000
Batch Threshold:		1000.000
Max Batch Discovery:	200
============================================================
Agent:		RE_LSPI
Policy:		eGreedy
Max LSPI Iterations:	10
Data Size:		5000
Weight Difference tol.:	0.001
Max Representation Expansion Iterations:	20
============================================================
Experiment:		OnlineExperiment
Output:			././13-results.txt
Learning Steps:		20000
Performance Checks:	4
Log Intervals:		60(s)
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1131.069, Density of A: 42.01%
2: L2_norm of weight difference = 1027.976, Density of A: 34.73%
3: L2_norm of weight difference = 1889.947, Density of A: 34.80%
4: L2_norm of weight difference = 2504.598, Density of A: 38.88%
5: L2_norm of weight difference = 619.739, Density of A: 33.95%
6: L2_norm of weight difference = 1963.561, Density of A: 35.31%
7: L2_norm of weight difference = 2582.952, Density of A: 40.19%
8: L2_norm of weight difference = 621.445, Density of A: 33.93%
9: L2_norm of weight difference = 2330.537, Density of A: 35.19%
10: L2_norm of weight difference = 2940.123, Density of A: 40.41%
Performance Check >>> 523.500 Return, 200 Steps, 21 Features
iFDD Batch: Max Relevance = 821.674
5000: E[0:04:45]-R[0:14:15]: Return=833.75, Steps=200, Features = 21
5000 >>> E[0:04:46]-R[0:14:18]: Return=543.25, Steps=200, Features = 21
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 365.113, Density of A: 18.90%
2: L2_norm of weight difference = 661.129, Density of A: 19.73%
3: L2_norm of weight difference = 630.632, Density of A: 17.78%
4: L2_norm of weight difference = 506.969, Density of A: 20.28%
5: L2_norm of weight difference = 697.286, Density of A: 17.72%
6: L2_norm of weight difference = 532.781, Density of A: 14.91%
7: L2_norm of weight difference = 273.425, Density of A: 19.39%
8: L2_norm of weight difference = 348.631, Density of A: 19.11%
9: L2_norm of weight difference = 613.077, Density of A: 19.27%
10: L2_norm of weight difference = 645.505, Density of A: 18.54%
Performance Check >>> 671.500 Return, 200 Steps, 21 Features
iFDD Batch: Max Relevance = 1246.819
New Feature 1: [3, 4], Relevance = 1246.819
New Feature 2: [18, 19], Relevance = 1243.615
New Feature 3: [11, 12], Relevance = 1071.453
New Feature 4: [7, 8], Relevance = 1062.016
New Feature 5: [3, 19], Relevance = 1051.066
New Feature 6: [17, 18], Relevance = 1028.503
New Feature 7: [3, 18], Relevance = 1025.185
New Feature 8: [0, 1], Relevance = 1014.524
New Feature 9: [13, 14], Relevance = 1013.533
New Feature 10: [1, 19], Relevance = 1000.976
Representation Expansion iteration #2
-----------------
Running LSPI:
1: L2_norm of weight difference = 385.274, Density of A: 9.17%
2: L2_norm of weight difference = 265.425, Density of A: 9.39%
3: L2_norm of weight difference = 229.573, Density of A: 9.18%
4: L2_norm of weight difference = 227.107, Density of A: 8.67%
5: L2_norm of weight difference = 726.807, Density of A: 9.32%
6: L2_norm of weight difference = 830.109, Density of A: 9.06%
7: L2_norm of weight difference = 1204.534, Density of A: 8.74%
8: L2_norm of weight difference = 1202.563, Density of A: 8.22%
9: L2_norm of weight difference = 183.597, Density of A: 9.13%
10: L2_norm of weight difference = 881.967, Density of A: 9.34%
Performance Check >>> 624.000 Return, 200 Steps, 31 Features
iFDD Batch: Max Relevance = 499.901
10000: E[0:14:03]-R[0:14:03]: Return=508.50, Steps=200, Features = 31
10000 >>> E[0:14:04]-R[0:14:04]: Return=711.00, Steps=200, Features = 31
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 467.038, Density of A: 10.02%
2: L2_norm of weight difference = 253.153, Density of A: 12.25%
3: L2_norm of weight difference = 273.460, Density of A: 11.53%
4: L2_norm of weight difference = 235.684, Density of A: 12.10%
5: L2_norm of weight difference = 380.661, Density of A: 12.72%
6: L2_norm of weight difference = 674.640, Density of A: 10.55%
7: L2_norm of weight difference = 702.951, Density of A: 11.10%
8: L2_norm of weight difference = 807.352, Density of A: 12.43%
9: L2_norm of weight difference = 883.147, Density of A: 10.63%
10: L2_norm of weight difference = 735.164, Density of A: 11.77%
Performance Check >>> 606.250 Return, 200 Steps, 31 Features
iFDD Batch: Max Relevance = 2071.686
New Feature 1: [5, 6], Relevance = 2071.686
New Feature 2: [6, 16], Relevance = 1965.873
New Feature 3: [6, 9], Relevance = 1944.011
New Feature 4: [4, 6], Relevance = 1857.449
New Feature 5: [2, 6], Relevance = 1844.323
New Feature 6: [6, 10], Relevance = 1832.862
New Feature 7: [9, 10], Relevance = 1816.913
New Feature 8: [2, 9], Relevance = 1810.561
New Feature 9: [2, 5], Relevance = 1780.010
New Feature 10: [2, 16], Relevance = 1769.787
New Feature 11: [5, 9], Relevance = 1749.321
New Feature 12: [9, 16], Relevance = 1740.843
New Feature 13: [4, 5], Relevance = 1711.733
New Feature 14: [2, 10], Relevance = 1710.412
New Feature 15: [15, 16], Relevance = 1709.953
New Feature 16: [0, 2], Relevance = 1689.874
New Feature 17: [2, 15], Relevance = 1689.535
New Feature 18: [0, 6], Relevance = 1683.601
New Feature 19: [2, 4], Relevance = 1670.423
New Feature 20: [6, 17], Relevance = 1661.734
New Feature 21: [4, 16], Relevance = 1660.919
New Feature 22: [6, 15], Relevance = 1651.004
New Feature 23: [2, 7, 8], Relevance = 1625.299
New Feature 24: [16, 17], Relevance = 1620.422
New Feature 25: [5, 10], Relevance = 1618.646
New Feature 26: [0, 16], Relevance = 1602.676
New Feature 27: [10, 16], Relevance = 1599.215
New Feature 28: [9, 15], Relevance = 1593.589
New Feature 29: [2, 17], Relevance = 1593.095
New Feature 30: [0, 5], Relevance = 1586.846
New Feature 31: [5, 16], Relevance = 1584.418
New Feature 32: [4, 9], Relevance = 1573.550
New Feature 33: [10, 17], Relevance = 1554.599
New Feature 34: [1, 6, 19], Relevance = 1548.288
New Feature 35: [0, 9], Relevance = 1547.403
New Feature 36: [6, 14], Relevance = 1541.728
New Feature 37: [0, 1, 19], Relevance = 1532.485
New Feature 38: [1, 2, 19], Relevance = 1529.651
New Feature 39: [0, 15], Relevance = 1517.431
New Feature 40: [1, 4, 19], Relevance = 1497.752
New Feature 41: [9, 17], Relevance = 1490.280
New Feature 42: [4, 10], Relevance = 1486.366
New Feature 43: [10, 15], Relevance = 1486.244
New Feature 44: [0, 4], Relevance = 1482.697
New Feature 45: [1, 16, 19], Relevance = 1477.901
New Feature 46: [4, 15], Relevance = 1477.330
New Feature 47: [5, 15], Relevance = 1470.874
New Feature 48: [0, 10], Relevance = 1465.869
New Feature 49: [9, 13, 14], Relevance = 1456.715
New Feature 50: [2, 3, 18], Relevance = 1441.433
New Feature 51: [3, 6, 18], Relevance = 1438.866
New Feature 52: [5, 17], Relevance = 1420.320
New Feature 53: [1, 5, 19], Relevance = 1414.845
New Feature 54: [6, 7], Relevance = 1413.159
New Feature 55: [7, 8, 9], Relevance = 1407.271
New Feature 56: [1, 10, 19], Relevance = 1406.167
New Feature 57: [6, 7, 8], Relevance = 1404.539
New Feature 58: [4, 17], Relevance = 1403.310
New Feature 59: [7, 8, 16], Relevance = 1385.681
New Feature 60: [3, 17, 18], Relevance = 1385.566
New Feature 61: [2, 11, 12], Relevance = 1382.009
New Feature 62: [3, 4, 18], Relevance = 1376.874
New Feature 63: [1, 17, 19], Relevance = 1366.582
New Feature 64: [9, 11, 12], Relevance = 1364.234
New Feature 65: [1, 9, 19], Relevance = 1356.096
New Feature 66: [0, 17], Relevance = 1355.708
New Feature 67: [3, 16, 18], Relevance = 1354.245
New Feature 68: [0, 3, 18], Relevance = 1352.516
New Feature 69: [15, 17], Relevance = 1345.953
New Feature 70: [0, 7, 8], Relevance = 1344.303
New Feature 71: [6, 11, 12], Relevance = 1343.978
New Feature 72: [2, 8], Relevance = 1343.377
New Feature 73: [1, 15, 19], Relevance = 1329.067
New Feature 74: [11, 12, 16], Relevance = 1327.725
New Feature 75: [5, 7, 8], Relevance = 1323.113
New Feature 76: [9, 14], Relevance = 1316.885
New Feature 77: [3, 10, 18], Relevance = 1314.258
New Feature 78: [10, 11, 12], Relevance = 1310.836
New Feature 79: [5, 11, 12], Relevance = 1309.227
New Feature 80: [7, 8, 10], Relevance = 1306.538
New Feature 81: [11, 12, 17], Relevance = 1302.969
New Feature 82: [3, 9, 18], Relevance = 1295.857
New Feature 83: [1, 11, 12, 19], Relevance = 1287.435
New Feature 84: [4, 11, 12], Relevance = 1280.475
New Feature 85: [3, 5, 18], Relevance = 1279.830
New Feature 86: [4, 7, 8], Relevance = 1275.748
New Feature 87: [1, 3, 18, 19], Relevance = 1274.221
New Feature 88: [2, 13, 14], Relevance = 1271.289
New Feature 89: [6, 12], Relevance = 1264.976
New Feature 90: [3, 15, 18], Relevance = 1264.057
New Feature 91: [5, 14], Relevance = 1250.525
New Feature 92: [10, 14], Relevance = 1246.824
New Feature 93: [7, 8, 15], Relevance = 1242.898
New Feature 94: [7, 8, 17], Relevance = 1242.481
New Feature 95: [0, 11, 12], Relevance = 1231.142
New Feature 96: [3, 11, 12, 18], Relevance = 1221.314
New Feature 97: [10, 13, 14], Relevance = 1219.557
New Feature 98: [1, 7, 8, 19], Relevance = 1218.502
New Feature 99: [2, 14], Relevance = 1205.178
New Feature 100: [8, 9], Relevance = 1202.206
New Feature 101: [5, 8], Relevance = 1200.927
New Feature 102: [13, 14, 17], Relevance = 1200.494
New Feature 103: [6, 13, 14], Relevance = 1196.872
New Feature 104: [5, 7], Relevance = 1192.771
New Feature 105: [13, 14, 16], Relevance = 1185.833
New Feature 106: [6, 8], Relevance = 1181.346
New Feature 107: [11, 12, 15], Relevance = 1180.334
New Feature 108: [14, 16], Relevance = 1179.848
New Feature 109: [2, 7], Relevance = 1175.173
New Feature 110: [3, 7, 8, 18], Relevance = 1151.490
New Feature 111: [14, 15], Relevance = 1144.510
New Feature 112: [7, 9], Relevance = 1138.985
New Feature 113: [5, 12], Relevance = 1119.083
New Feature 114: [9, 12], Relevance = 1106.389
New Feature 115: [13, 14, 15], Relevance = 1105.871
New Feature 116: [5, 13, 14], Relevance = 1098.504
New Feature 117: [7, 10], Relevance = 1093.855
New Feature 118: [4, 7], Relevance = 1080.401
New Feature 119: [6, 11], Relevance = 1076.906
New Feature 120: [4, 13, 14], Relevance = 1071.915
New Feature 121: [0, 13, 14], Relevance = 1071.143
New Feature 122: [7, 16], Relevance = 1067.573
New Feature 123: [7, 8, 11, 12], Relevance = 1063.486
New Feature 124: [2, 3, 4], Relevance = 1063.302
New Feature 125: [4, 19], Relevance = 1060.444
New Feature 126: [16, 19], Relevance = 1060.106
New Feature 127: [2, 12], Relevance = 1052.319
New Feature 128: [11, 12, 13, 14], Relevance = 1050.925
New Feature 129: [4, 12], Relevance = 1049.979
New Feature 130: [6, 19], Relevance = 1045.457
New Feature 131: [8, 16], Relevance = 1037.459
New Feature 132: [4, 14], Relevance = 1034.457
New Feature 133: [5, 19], Relevance = 1023.806
New Feature 134: [8, 10], Relevance = 1015.237
New Feature 135: [3, 13, 14, 18], Relevance = 1012.868
New Feature 136: [0, 19], Relevance = 1012.605
New Feature 137: [1, 13, 14, 19], Relevance = 1010.421
New Feature 138: [4, 8], Relevance = 1008.376
New Feature 139: [2, 11], Relevance = 1005.675
New Feature 140: [1, 2], Relevance = 1005.545
New Feature 141: [7, 17], Relevance = 1002.753
Representation Expansion iteration #2
-----------------
Running LSPI:
1: L2_norm of weight difference = 1098.921, Density of A: 0.44%
2: L2_norm of weight difference = 625.217, Density of A: 0.44%
3: L2_norm of weight difference = 664.016, Density of A: 0.44%
4: L2_norm of weight difference = 665.328, Density of A: 0.44%
5: L2_norm of weight difference = 691.875, Density of A: 0.44%
6: L2_norm of weight difference = 729.502, Density of A: 0.44%
7: L2_norm of weight difference = 697.640, Density of A: 0.44%
8: L2_norm of weight difference = 648.093, Density of A: 0.44%
9: L2_norm of weight difference = 674.960, Density of A: 0.44%
10: L2_norm of weight difference = 681.325, Density of A: 0.44%
Performance Check >>> 737.750 Return, 200 Steps, 172 Features
iFDD Batch: Max Relevance = 601.229
15000: E[4:16:40]-R[1:25:33]: Return=692.75, Steps=200, Features = 172
15000 >>> E[4:16:41]-R[1:25:34]: Return=660.00, Steps=200, Features = 172
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1216.094, Density of A: 0.46%
2: L2_norm of weight difference = 912.296, Density of A: 0.46%
3: L2_norm of weight difference = 888.842, Density of A: 0.46%
4: L2_norm of weight difference = 871.093, Density of A: 0.46%
5: L2_norm of weight difference = 844.931, Density of A: 0.46%
6: L2_norm of weight difference = 911.092, Density of A: 0.46%
7: L2_norm of weight difference = 984.553, Density of A: 0.46%
8: L2_norm of weight difference = 1012.605, Density of A: 0.46%
9: L2_norm of weight difference = 1101.365, Density of A: 0.46%
10: L2_norm of weight difference = 1084.295, Density of A: 0.46%
Performance Check >>> 816.500 Return, 200 Steps, 172 Features
iFDD Batch: Max Relevance = 758.368
20000: E[8:17:09]-R[0:00:00]: Return=738.50, Steps=200, Features = 172
20000 >>> E[8:17:10]-R[0:00:00]: Return=832.25, Steps=200, Features = 172
============================================================
Took 8:17:10
Results	=> ././13-results.txt
Log	=> ././13-out.txt