============================================================
Domain:		SystemAdministrator
Dimensions:	20
|S|:		1048576
|A|:		21
|S|x|A|:		22020096
Episode Cap:	200
Gamma:		0.95
Computers:	20
Edges:		[(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10), (10, 11), (11, 12), (12, 13), (13, 14), (14, 15), (15, 16), (16, 17), (17, 18), (18, 19), (0, 19)]
Neighbors:
0 : [1, 19]
1 : [0, 2]
2 : [1, 3]
3 : [2, 4]
4 : [3, 5]
5 : [4, 6]
6 : [5, 7]
7 : [6, 8]
8 : [7, 9]
9 : [8, 10]
10 : [9, 11]
11 : [10, 12]
12 : [11, 13]
13 : [12, 14]
14 : [13, 15]
15 : [14, 16]
16 : [15, 17]
17 : [16, 18]
18 : [17, 19]
19 : [18, 0]
============================================================
Representation:		IndependentDiscretizationCompactBinary
Features per action:	21
Binary Dimensions:	[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]
============================================================
Agent:		RE_LSPI
Policy:		eGreedy
Max LSPI Iterations:	10
Data Size:		5000
Weight Difference tol.:	0.001
Max Representation Expansion Iterations:	20
============================================================
Experiment:		OnlineExperiment
Output:			././7-results.txt
Learning Steps:		5000
Performance Checks:	1
Log Intervals:		60(s)
Representation Expansion iteration #1
-----------------
Running LSPI:
1: L2_norm of weight difference = 1410.439, Density of A: 41.20%
2: L2_norm of weight difference = 1306.284, Density of A: 37.60%
3: L2_norm of weight difference = 2599.808, Density of A: 40.32%
4: L2_norm of weight difference = 3305.673, Density of A: 42.13%
5: L2_norm of weight difference = 708.744, Density of A: 36.69%
6: L2_norm of weight difference = 1360.242, Density of A: 40.23%
7: L2_norm of weight difference = 2082.460, Density of A: 41.48%
8: L2_norm of weight difference = 725.681, Density of A: 36.92%
9: L2_norm of weight difference = 1173.250, Density of A: 39.29%
10: L2_norm of weight difference = 1889.893, Density of A: 41.21%
Performance Check >>> 432.250 Return, 200 Steps, 21 Features
5000: E[0:01:38]-R[0:00:00]: Return=789.75, Steps=200, Features = 21
5000 >>> E[0:01:39]-R[0:00:00]: Return=597.75, Steps=200, Features = 21
============================================================
Took 0:01:39
Results	=> ././7-results.txt
Log	=> ././7-out.txt
