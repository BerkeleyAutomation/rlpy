============================================================
Domain:		BlocksWorld
Dimensions:	6
|S|:		46656
|A|:		36
|S|x|A|:		1679616
Episode Cap:	1000
Gamma:		1
noise		0.3
blocks		6
============================================================
Representation:		IndependentDiscretizationCompactBinary
Features per action:	37
Binary Dimensions:	[]
============================================================
Representation:		iFDD
Features per action:	37
Initial Representation:	IndependentDiscretizationCompactBinary
Plus:			0
Sparsify:		1
Cached:			1
Online Threshold:	1.000
Batch Threshold:		1.000
Max Batch Discovery:	100
============================================================
Agent:		SARSA
Policy:		eGreedy
boyan_N0: 100.0
Alpha_0:		0.10
Decay mode:		boyan
============================================================
Experiment:		OnlineExperiment
Output:			././26-results.txt
Learning Steps:		100000
Performance Checks:	10
Log Intervals:		60(s)
10000 >>> E[0:01:01]-R[0:09:08]: Return=-1.00, Steps=1000, Features = 52
20000: E[0:02:05]-R[0:08:21]: Return=-1.00, Steps=1000, Features = 52
20000 >>> E[0:02:07]-R[0:08:29]: Return=-1.00, Steps=1000, Features = 52
30000: E[0:03:12]-R[0:07:28]: Return=-1.00, Steps=1000, Features = 52
30000 >>> E[0:03:14]-R[0:07:33]: Return=-1.00, Steps=1000, Features = 52
39000: E[0:04:15]-R[0:06:39]: Return=-1.00, Steps=1000, Features = 56
40000 >>> E[0:04:25]-R[0:06:37]: Return=-1.00, Steps=1000, Features = 56
49000: E[0:05:28]-R[0:05:42]: Return=-1.00, Steps=1000, Features = 65
50000 >>> E[0:05:38]-R[0:05:38]: Return=-1.00, Steps=1000, Features = 67
59000: E[0:06:46]-R[0:04:42]: Return=-1.00, Steps=1000, Features = 71
60000 >>> E[0:06:56]-R[0:04:37]: Return=-1.00, Steps=1000, Features = 71
68000: E[0:07:57]-R[0:03:44]: Return=-1.00, Steps=1000, Features = 72
70000 >>> E[0:08:14]-R[0:03:32]: Return=-1.00, Steps=1000, Features = 72
78000: E[0:09:17]-R[0:02:37]: Return=-1.00, Steps=1000, Features = 73
80000 >>> E[0:09:35]-R[0:02:24]: Return=-1.00, Steps=1000, Features = 73
88000: E[0:10:37]-R[0:01:27]: Return=-1.00, Steps=1000, Features = 75
90000 >>> E[0:10:56]-R[0:01:13]: Return=-1.00, Steps=1000, Features = 75
98000: E[0:11:59]-R[0:00:15]: Return=-1.00, Steps=1000, Features = 79
100000 >>> E[0:12:18]-R[0:00:00]: Return=-1.00, Steps=1000, Features = 80
============================================================
Took 0:12:18
Results	=> ././26-results.txt
Log	=> ././26-out.txt
