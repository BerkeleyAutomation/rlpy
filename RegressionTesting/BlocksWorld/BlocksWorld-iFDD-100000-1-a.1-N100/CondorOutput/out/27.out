============================================================
Domain:		BlocksWorld
Dimensions:	6
|S|:		46656
|A|:		36
|S|x|A|:		1679616
Episode Cap:	1000
Gamma:		1
noise		0.3
blocks		6
============================================================
Representation:		IndependentDiscretizationCompactBinary
Features per action:	37
Binary Dimensions:	[]
============================================================
Representation:		iFDD
Features per action:	37
Initial Representation:	IndependentDiscretizationCompactBinary
Plus:			0
Sparsify:		1
Cached:			1
Online Threshold:	1.000
Batch Threshold:		1.000
Max Batch Discovery:	100
============================================================
Agent:		SARSA
Policy:		eGreedy
boyan_N0: 100.0
Alpha_0:		0.10
Decay mode:		boyan
============================================================
Experiment:		OnlineExperiment
Output:			././27-results.txt
Learning Steps:		100000
Performance Checks:	10
Log Intervals:		60(s)
10000 >>> E[0:00:59]-R[0:08:54]: Return=-1.00, Steps=1000, Features = 52
20000: E[0:02:02]-R[0:08:06]: Return=-1.00, Steps=1000, Features = 52
20000 >>> E[0:02:04]-R[0:08:14]: Return=-1.00, Steps=1000, Features = 52
30000: E[0:03:07]-R[0:07:15]: Return=-1.00, Steps=1000, Features = 52
30000 >>> E[0:03:09]-R[0:07:20]: Return=-1.00, Steps=1000, Features = 52
40000: E[0:04:14]-R[0:06:21]: Return=-1.00, Steps=1000, Features = 57
40000 >>> E[0:04:16]-R[0:06:24]: Return=-1.00, Steps=1000, Features = 57
49000: E[0:05:19]-R[0:05:32]: Return=-1.00, Steps=1000, Features = 64
50000 >>> E[0:05:28]-R[0:05:28]: Return=-1.00, Steps=1000, Features = 66
59000: E[0:06:34]-R[0:04:34]: Return=-1.00, Steps=1000, Features = 68
60000 >>> E[0:06:43]-R[0:04:29]: Return=-1.00, Steps=1000, Features = 68
69000: E[0:07:50]-R[0:03:31]: Return=-1.00, Steps=1000, Features = 69
70000 >>> E[0:07:59]-R[0:03:25]: Return=-1.00, Steps=1000, Features = 70
78000: E[0:09:00]-R[0:02:32]: Return=-1.00, Steps=1000, Features = 79
80000 >>> E[0:09:18]-R[0:02:19]: Return=-1.00, Steps=1000, Features = 79
88000: E[0:10:21]-R[0:01:25]: Return=-1.00, Steps=1000, Features = 83
90000 >>> E[0:10:40]-R[0:01:11]: Return=-1.00, Steps=1000, Features = 85
98000: E[0:11:46]-R[0:00:14]: Return=-1.00, Steps=1000, Features = 88
100000 >>> E[0:12:05]-R[0:00:00]: Return=-1.00, Steps=1000, Features = 89
============================================================
Took 0:12:05
Results	=> ././27-results.txt
Log	=> ././27-out.txt
